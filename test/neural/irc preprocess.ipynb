{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre IRC\n",
    "\n",
    "a notebook to convert the mat data file (with neural data) into (states, actions, tasks) for IRC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('../../privateconfig'))\n",
    "resdir = Path(config['Datafolder']['data'])\n",
    "workdir = Path(config['Codefolder']['workspace'])\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24455\\miniconda3\\envs\\lab\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\24455\\miniconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\Users\\24455\\miniconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from notification import notify\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# const\n",
    "bin_size = 17 # how many bin of DT. about 0.1 s\n",
    "num_bins = 24 # how many bins to use. use 2.4 s and discard the long trials.\n",
    "monkey_height = 10\n",
    "DT = 0.006 # DT for raw data\n",
    "reward_boundary = 65\n",
    "areas = ['PPC', 'PFC', 'MST']\n",
    "t_total = 24\n",
    "fontsize = 7; lw = 1\n",
    "\n",
    "m = 'm53'\n",
    "locals().update({m: {}})\n",
    "figure_path = resdir/'figures'\n",
    "datapaths = [i for i in Path(resdir/'mat_ruiyi').glob(f'{m}*.mat')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def set_violin_plot(vp, facecolor, edgecolor, linewidth=1, alpha=1, ls='-', hatch=r''):\n",
    "    plt.setp(vp['bodies'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha ,ls=ls, hatch=hatch)\n",
    "    plt.setp(vp['cmins'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha)\n",
    "    plt.setp(vp['cmaxes'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha)\n",
    "    plt.setp(vp['cbars'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha)\n",
    "    \n",
    "    linecolor = 'k' if facecolor == 'None' else 'snow'\n",
    "    if 'cmedians' in vp:\n",
    "        plt.setp(vp['cmedians'], facecolor=linecolor, edgecolor=linecolor, \n",
    "                 linewidth=linewidth, alpha=alpha)\n",
    "    if 'cmeans' in vp:\n",
    "        plt.setp(vp['cmeans'], facecolor=linecolor, edgecolor=linecolor, \n",
    "                 linewidth=linewidth, alpha=alpha)\n",
    "       \n",
    "        \n",
    "def downsample(data, bin_size=20):\n",
    "    num_bin = data.shape[0] // bin_size\n",
    "    data_ = data[:bin_size * num_bin]\n",
    "    data_ = data_.reshape(num_bin, bin_size, data.shape[-1])\n",
    "    data_ = np.nanmean(data_, axis=1)\n",
    "    return data_\n",
    "\n",
    "\n",
    "def convert_location_to_relative(\n",
    "        mx,\n",
    "        my,\n",
    "        body_theta,\n",
    "        x_fly,\n",
    "        y_fly,\n",
    "        dt=0.1\n",
    "\n",
    "):\n",
    "    '''\n",
    "        calculate relative beliefs and states\n",
    "    '''\n",
    "\n",
    "    x_fly_rel = x_fly - mx\n",
    "    y_fly_rel = y_fly - my\n",
    "    phi = body_theta.reshape(-1)\n",
    "    R = lambda theta : np.array([[np.cos(theta/180*np.pi),-np.sin(theta/180*np.pi)],[np.sin(theta/180*np.pi),np.cos(theta/180*np.pi)]])\n",
    "    XY = np.zeros((2,x_fly_rel.shape[0]))\n",
    "    XY[0,:] = x_fly_rel.reshape(-1)\n",
    "    XY[1,:] = y_fly_rel.reshape(-1)\n",
    "    rot = R(phi)\n",
    "    XY = np.einsum('ijk,jk->ik', rot, XY)\n",
    "    xfp_rel= XY[0, :]\n",
    "    yfp_rel = XY[1, :]\n",
    "    \n",
    "    return xfp_rel,yfp_rel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_location_to_angle(gaze_r, gaze_x, gaze_y, body_theta, body_x, body_y, hor_theta_eye, ver_theta_eye,DT=DT, remove_pre=True):\n",
    "    '''\n",
    "        convert the world overhead view location of the 'gaze' location to eye coord. \n",
    "\n",
    "        gaze location, the target\n",
    "        gaze_r, relative distance\n",
    "        gaze_x, gaze location x\n",
    "        gaze_y,\n",
    "\n",
    "        body_theta, heading direction\n",
    "        body_x, monkey location x\n",
    "        body_y, \n",
    "\n",
    "        hor_theta_eye, actual eye location in eye coord. used here to remove pre saccade (when monkey hasnt seen the target yet)\n",
    "        ver_theta_eye\n",
    "    '''\n",
    "\n",
    "    #hor_theta = -np.rad2deg(np.arctan2(-(gaze_x - body_x), gaze_y - body_y) - (body_theta-np.deg2rad(90))).reshape(-1, 1) \n",
    "    hor_theta = -np.rad2deg(np.arctan2(-(gaze_x - body_x), np.sqrt((gaze_y - body_y)**2 + monkey_height**2))\n",
    "                            - (body_theta-np.deg2rad(90))).reshape(-1, 1) \n",
    "    overshoot_idx = np.where(((gaze_x - body_x) * gaze_x < 0) | (gaze_y < body_y)\n",
    "                             #| (abs(hor_theta.flatten()) > 60)\n",
    "                            )[0]\n",
    "    \n",
    "    if overshoot_idx.size > 0:\n",
    "        hor_theta[overshoot_idx[0]:] = np.nan\n",
    "\n",
    "    k = -1 / np.tan(body_theta); b = body_y - k * body_x\n",
    "    gaze_r_sign = (k * gaze_x + b < gaze_y).astype(int)\n",
    "    gaze_r_sign[gaze_r_sign == 0] = -1\n",
    "    ver_theta = -np.rad2deg(np.arctan2(monkey_height, gaze_r_sign * gaze_r)).reshape(-1, 1)\n",
    "    overshoot_idx = np.where((gaze_r_sign < 0)\n",
    "                             #| (abs(ver_theta.flatten()) > 60)\n",
    "                            )[0]\n",
    "    if overshoot_idx.size > 0:\n",
    "        ver_theta[overshoot_idx[0]:] = np.nan\n",
    "        \n",
    "    # detect saccade\n",
    "    if remove_pre:\n",
    "        if hor_theta_eye.size > 2:\n",
    "            saccade = np.sqrt((np.gradient(hor_theta_eye) / DT)**2 + \n",
    "                            (np.gradient(ver_theta_eye) / DT)**2)\n",
    "            saccade_start_idx = np.where(saccade > 100)[0]\n",
    "            saccade_start_idx = saccade_start_idx[0] + 16 if saccade_start_idx.size > 0 else None\n",
    "\n",
    "            hor_theta[:saccade_start_idx] = np.nan\n",
    "            ver_theta[:saccade_start_idx] = np.nan\n",
    "        \n",
    "    return hor_theta, ver_theta\n",
    "\n",
    "\n",
    "def compute_error(data1, data2, mask):\n",
    "    #data1 = data1[~mask]; data2 = data2[~mask]\n",
    "    #corr = np.corrcoef(data1, data2)\n",
    "    error = abs(data1 - data2)\n",
    "    \n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    data1_ = data1.copy(); data2_ = data2.copy()\n",
    "    rng.shuffle(data1_); rng.shuffle(data2_)\n",
    "    error_shuffle = abs(data1_ - data2_)\n",
    "    return error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "\n",
    "for idx, datapath in enumerate(datapaths):\n",
    "    if datapath.stem[-1].isalpha():\n",
    "        continue\n",
    "    data = loadmat(datapath)\n",
    "    eval(m)[datapath.stem] = data\n",
    "    notify(datapath)\n",
    "    \n",
    "notify('all done! loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_extracted_continuous = {}; m_downsampled = {}; m_errors = {}\n",
    "for key, data in eval(m).items():\n",
    "    if key[-1].isalpha():\n",
    "        continue\n",
    "        \n",
    "    trials_behv = data['trials_behv'][0]\n",
    "    trials_units = data['units'][0]\n",
    "    units_area = np.array([v[0] for v in trials_units['brain_area']])\n",
    "    \n",
    "    Ydownsampled = []\n",
    "    Y = []\n",
    "    trials_error = []; trials_error_sign = []; trials_target_angle = []; trials_target_distance = []\n",
    "    for trial_idx, trial_behv in enumerate(trials_behv):\n",
    "        \n",
    "        trial_ts = trial_behv['continuous']['ts'][0][0].reshape(-1)\n",
    "        t_mask = (trial_ts > 0) & (~np.isnan(trial_behv['continuous']['ymp'][0][0].reshape(-1)))\n",
    "        t_mask &= trial_ts < trial_behv['events']['t_stop'][0][0].reshape(-1)\n",
    "        if t_mask.sum() > 0:\n",
    "            t_mask[np.where(t_mask == True)[0][0]] = False # remove the first data point to avoid downsample error\n",
    "        \n",
    "        # get Y\n",
    "        mx = trial_behv['continuous']['xmp'][0][0][t_mask]\n",
    "        my = trial_behv['continuous']['ymp'][0][0][t_mask]\n",
    "        fx = trial_behv['continuous']['xfp'][0][0][t_mask]\n",
    "        fy = trial_behv['continuous']['yfp'][0][0][t_mask]\n",
    "        sx = np.ones_like(fx); sy = np.ones_like(fy)\n",
    "        if my.size > 0:\n",
    "            fx = np.ones_like(fx) * fx[0]\n",
    "            fy = np.ones_like(fy) * fy[0]\n",
    "            sx *= mx[-1]; sy *= my[-1]\n",
    "            my = my + 30; fy = fy + 30; sy = sy + 30\n",
    "        \n",
    "        dx = fx - mx; dy = fy - my\n",
    "        rel_dist = np.sqrt(dx**2 + dy**2); rel_ang = np.rad2deg(np.arctan2(dy, dx))\n",
    "        rel_dist_stop = np.sqrt((sx - mx)**2 + (sy - my)**2)\n",
    "        \n",
    "        if my.size > 0:\n",
    "            trials_error.append(rel_dist[-1][0])\n",
    "            trials_error_sign.append(rel_dist[-1][0])\n",
    "            trials_target_angle.append(np.rad2deg(np.arctan2(fy, fx))[-1][0] - 90)\n",
    "            trials_target_distance.append(np.sqrt(fx**2 + fy**2)[-1][0])\n",
    "            \n",
    "        else:\n",
    "            trials_error.append(np.nan)\n",
    "            trials_error_sign.append(np.nan)\n",
    "            trials_target_angle.append(np.nan)\n",
    "            trials_target_distance.append(np.nan)\n",
    "        \n",
    "        if my.size > 0:\n",
    "            d1 = np.sqrt(fx**2 + fy**2)\n",
    "            r1 = (fx**2 + fy**2) / (2*fx)\n",
    "            radian1 = 2 * r1 * np.arcsin(d1 / (2 * r1))\n",
    "\n",
    "            d2 = np.sqrt(mx**2 + my**2)\n",
    "            r2 = (mx**2 + my**2) / (2*mx + 1e-8)\n",
    "            radian2 = 2 * r2 * np.arcsin(d2 / (2 * r2 + 1e-8))\n",
    "\n",
    "            sign = np.ones_like(rel_dist)\n",
    "            sign[radian2 < radian1] = -1\n",
    "            rel_dist = sign * rel_dist\n",
    "            trials_error_sign[-1] = rel_dist[-1][0]\n",
    "        \n",
    "        abs_dist = np.sqrt(mx**2 + my**2); abs_ang = np.rad2deg(np.arctan2(my, mx))\n",
    "\n",
    "        hor_theta = trial_behv['continuous']['yre'][0][0][t_mask]\n",
    "        ver_theta = trial_behv['continuous']['zre'][0][0][t_mask]\n",
    "        mw = -trial_behv['continuous']['w'][0][0][t_mask].reshape(-1)\n",
    "        body_theta = np.deg2rad(np.cumsum(mw) * DT + 90)\n",
    "        body_x, body_y = mx.reshape(-1), my.reshape(-1)\n",
    "        \n",
    "        hor_theta_, ver_theta_ = convert_location_to_angle(abs(rel_dist).reshape(-1), fx.reshape(-1), fy.reshape(-1),\n",
    "                                                           body_theta, body_x, body_y, \n",
    "                                                           hor_theta.reshape(-1), ver_theta.reshape(-1))\n",
    "        \n",
    "        target_variable = np.hstack([rel_dist, rel_ang, abs_dist, abs_ang,\n",
    "                                     hor_theta, ver_theta, hor_theta_, ver_theta_,\n",
    "                                     fx, fy, mx, my])\n",
    "        Y.append(target_variable)\n",
    "        target_variable = downsample(target_variable, bin_size=bin_size)\n",
    "        \n",
    "        # filter trials\n",
    "        mv = trial_behv['continuous']['v'][0][0][t_mask].reshape(-1)\n",
    "        #if t_mask.sum() * DT > 3.5 or t_mask.sum() * DT < 0.6 or mv.max() < 50 or abs_dist[-1] < 50 or \\\n",
    "        #   trial_behv['prs']['floordensity'] != 0.0001:\n",
    "        \n",
    "        Ydownsampled.append([trial_idx, target_variable])\n",
    "   \n",
    "    m_extracted_continuous[key + 'Y'] = Y\n",
    "    m_downsampled[key + 'Ydownsampled'] = Ydownsampled\n",
    "\n",
    "    m_errors[key + 'error'] = trials_error; m_errors[key + 'error_sign'] = trials_error_sign\n",
    "    m_errors[key + 'target_angle'] = trials_target_angle; m_errors[key + 'target_distance'] = trials_target_distance\n",
    "    \n",
    "eval(m).update(m_downsampled); eval(m).update(m_extracted_continuous); eval(m).update(m_errors)\n",
    "del m_downsampled, m_extracted_continuous, m_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18.17028988,  13.54595083,  17.01861578,  18.68416629,\n",
       "        26.74390142,  22.20859741,  21.47015695,  21.83848936,\n",
       "        -3.14449769, -11.68081328, -11.97708461, -12.61934718,\n",
       "       -13.08344555, -15.71505653, -19.2684775 , -19.14812021,\n",
       "       -18.84932843, -27.07255835, -33.1027666 , -33.19149107,\n",
       "       -33.41326209, -34.64067414, -34.7164632 , -33.41274576,\n",
       "       -30.23594542, -27.07115061, -23.98504504, -21.02565305,\n",
       "       -18.2409917 , -15.67907816, -13.38792947, -11.41556257,\n",
       "        -9.8099947 ,  -8.61923857,  -7.89130629,  -8.00454586,\n",
       "        -8.33482501,  -8.51964894,  -8.70167934,  -8.64319324,\n",
       "        -9.51661559, -12.69209088, -17.26120657, -19.8102739 ,\n",
       "       -21.26771501, -23.53762627, -21.99809276, -20.03528034,\n",
       "       -17.0047944 , -11.68227386,  -3.96379236,   6.29052289,\n",
       "        30.58844802,  36.78825109,  35.47496437,  30.57994809,\n",
       "        23.19037931,  14.08145198,   4.02847159,  -6.19325235,\n",
       "       -15.80841087, -24.04169217, -30.11776801, -33.18191371,\n",
       "       -31.94150712, -30.51658888, -29.76690663, -21.31958602])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yd=eval(m)['m53s105Ydownsampled']\n",
    "y=eval(m)['m53s105Y']\n",
    "\n",
    "len(yd), len(y)\n",
    "yd[0][1][:,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m53s105Ydownsampled\n",
      "m53s113Ydownsampled\n",
      "m53s115Ydownsampled\n",
      "m53s124Ydownsampled\n",
      "m53s91Ydownsampled\n",
      "m53s93Ydownsampled\n",
      "m53s97Ydownsampled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key, data in eval(m).items():\n",
    "    if not key.endswith('Ydownsampled'):\n",
    "        continue\n",
    "    print(key)\n",
    "    y=eval(m)[key]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
