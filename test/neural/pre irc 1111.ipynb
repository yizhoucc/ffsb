{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre IRC\n",
    "\n",
    "## outline:\n",
    "\n",
    "- pre IRC\n",
    "    - load mat (the neural recording file with behavior)\n",
    "    - convert to IRC input (state, action, task)\n",
    "- IRC (terminal script)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('../../privateconfig'))\n",
    "resdir = Path(config['Datafolder']['data'])\n",
    "workdir = Path(config['Codefolder']['workspace'])\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24455\\miniconda3\\envs\\lab\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\24455\\miniconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\Users\\24455\\miniconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from notification import notify\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from plot_ult import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/24455/Desktop/repo/mkdata/m51_mat_ruiyi/m51s38.mat'),\n",
       " WindowsPath('C:/Users/24455/Desktop/repo/mkdata/m51_mat_ruiyi/m51s40.mat'),\n",
       " WindowsPath('C:/Users/24455/Desktop/repo/mkdata/m51_mat_ruiyi/m51s41.mat'),\n",
       " WindowsPath('C:/Users/24455/Desktop/repo/mkdata/m51_mat_ruiyi/m51s42.mat'),\n",
       " WindowsPath('C:/Users/24455/Desktop/repo/mkdata/m51_mat_ruiyi/m51s43.mat')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# const\n",
    "bin_size = 17 # how many bin of DT. about 0.1 s\n",
    "num_bins = 24 # how many bins to use. use 2.4 s and discard the long trials.\n",
    "monkey_height = 10\n",
    "DT = 0.006 # DT for raw data\n",
    "reward_boundary = 65\n",
    "areas = ['PPC', 'PFC', 'MST']\n",
    "t_total = 24\n",
    "fontsize = 7; lw = 1\n",
    "worldscale =200\n",
    "\n",
    "m = 'm51'\n",
    "folder='m51_mat_ruiyi'\n",
    "dens=[0.0001, 0.0005, 0.001,  0.005 ]\n",
    "idensity=3\n",
    "density=dens[idensity]\n",
    "locals().update({m: {}})\n",
    "figure_path = resdir/'figures'\n",
    "# datapaths = [i for i in Path(resdir/'mat_ruiyi').glob(f'{m}*.mat')]\n",
    "datapaths=[i for i in Path(resdir/folder).glob(f'{m}*.mat')]\n",
    "datapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def set_violin_plot(vp, facecolor, edgecolor, linewidth=1, alpha=1, ls='-', hatch=r''):\n",
    "    plt.setp(vp['bodies'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha ,ls=ls, hatch=hatch)\n",
    "    plt.setp(vp['cmins'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha)\n",
    "    plt.setp(vp['cmaxes'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha)\n",
    "    plt.setp(vp['cbars'], facecolor=facecolor, edgecolor=edgecolor, \n",
    "             linewidth=linewidth, alpha=alpha)\n",
    "    \n",
    "    linecolor = 'k' if facecolor == 'None' else 'snow'\n",
    "    if 'cmedians' in vp:\n",
    "        plt.setp(vp['cmedians'], facecolor=linecolor, edgecolor=linecolor, \n",
    "                 linewidth=linewidth, alpha=alpha)\n",
    "    if 'cmeans' in vp:\n",
    "        plt.setp(vp['cmeans'], facecolor=linecolor, edgecolor=linecolor, \n",
    "                 linewidth=linewidth, alpha=alpha)\n",
    "       \n",
    "        \n",
    "def downsample(data, bin_size=20):\n",
    "    num_bin = data.shape[0] // bin_size\n",
    "    data_ = data[:bin_size * num_bin]\n",
    "    data_ = data_.reshape(num_bin, bin_size, data.shape[-1])\n",
    "    data_ = np.nanmean(data_, axis=1)\n",
    "    return data_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_location_to_angle(gaze_r, gaze_x, gaze_y, body_theta, body_x, body_y, hor_theta_eye, ver_theta_eye,DT=DT, remove_pre=True):\n",
    "    '''\n",
    "        convert the world overhead view location of the 'gaze' location to eye coord. \n",
    "\n",
    "        gaze location, the target\n",
    "        gaze_r, relative distance\n",
    "        gaze_x, gaze location x\n",
    "        gaze_y,\n",
    "\n",
    "        body_theta, heading direction\n",
    "        body_x, monkey location x\n",
    "        body_y, \n",
    "\n",
    "        hor_theta_eye, actual eye location in eye coord. used here to remove pre saccade (when monkey hasnt seen the target yet)\n",
    "        ver_theta_eye\n",
    "    '''\n",
    "\n",
    "    #hor_theta = -np.rad2deg(np.arctan2(-(gaze_x - body_x), gaze_y - body_y) - (body_theta-np.deg2rad(90))).reshape(-1, 1) \n",
    "    hor_theta = -np.rad2deg(np.arctan2(-(gaze_x - body_x), np.sqrt((gaze_y - body_y)**2 + monkey_height**2))\n",
    "                            - (body_theta-np.deg2rad(90))).reshape(-1, 1) \n",
    "    overshoot_idx = np.where(((gaze_x - body_x) * gaze_x < 0) | (gaze_y < body_y)\n",
    "                             #| (abs(hor_theta.flatten()) > 60)\n",
    "                            )[0]\n",
    "    \n",
    "    if overshoot_idx.size > 0:\n",
    "        hor_theta[overshoot_idx[0]:] = np.nan\n",
    "\n",
    "    k = -1 / np.tan(body_theta); b = body_y - k * body_x\n",
    "    gaze_r_sign = (k * gaze_x + b < gaze_y).astype(int)\n",
    "    gaze_r_sign[gaze_r_sign == 0] = -1\n",
    "    ver_theta = -np.rad2deg(np.arctan2(monkey_height, gaze_r_sign * gaze_r)).reshape(-1, 1)\n",
    "    overshoot_idx = np.where((gaze_r_sign < 0)\n",
    "                             #| (abs(ver_theta.flatten()) > 60)\n",
    "                            )[0]\n",
    "    if overshoot_idx.size > 0:\n",
    "        ver_theta[overshoot_idx[0]:] = np.nan\n",
    "        \n",
    "    # detect saccade\n",
    "    if remove_pre:\n",
    "        if hor_theta_eye.size > 2:\n",
    "            saccade = np.sqrt((np.gradient(hor_theta_eye) / DT)**2 + \n",
    "                            (np.gradient(ver_theta_eye) / DT)**2)\n",
    "            saccade_start_idx = np.where(saccade > 100)[0]\n",
    "            saccade_start_idx = saccade_start_idx[0] + 16 if saccade_start_idx.size > 0 else None\n",
    "\n",
    "            hor_theta[:saccade_start_idx] = np.nan\n",
    "            ver_theta[:saccade_start_idx] = np.nan\n",
    "        \n",
    "    return hor_theta, ver_theta\n",
    "\n",
    "\n",
    "def compute_error(data1, data2, mask):\n",
    "    #data1 = data1[~mask]; data2 = data2[~mask]\n",
    "    #corr = np.corrcoef(data1, data2)\n",
    "    error = abs(data1 - data2)\n",
    "    \n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    data1_ = data1.copy(); data2_ = data2.copy()\n",
    "    rng.shuffle(data1_); rng.shuffle(data2_)\n",
    "    error_shuffle = abs(data1_ - data2_)\n",
    "    return error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load raw data (same as ruiyi script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "\n",
    "for idx, datapath in enumerate(datapaths):\n",
    "    if datapath.stem[-1].isalpha():\n",
    "        continue\n",
    "    data = loadmat(datapath)\n",
    "    eval(m)[datapath.stem] = data\n",
    "    notify(datapath)\n",
    "    \n",
    "notify('all done! loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_extracted_continuous = {}; m_downsampled = {}; m_errors = {}\n",
    "for key, data in eval(m).items():\n",
    "    if key[-1].isalpha():\n",
    "        continue\n",
    "        \n",
    "    trials_behv = data['trials_behv'][0]\n",
    "    trials_units = data['units'][0]\n",
    "    units_area = np.array([v[0] for v in trials_units['brain_area']])\n",
    "    \n",
    "    Ydownsampled = []\n",
    "    Y = []\n",
    "    trials_error = []; trials_error_sign = []; trials_target_angle = []; trials_target_distance = []\n",
    "    for trial_idx, trial_behv in enumerate(trials_behv):\n",
    "        \n",
    "        trial_ts = trial_behv['continuous']['ts'][0][0].reshape(-1)\n",
    "        t_mask = (trial_ts > 0) & (~np.isnan(trial_behv['continuous']['ymp'][0][0].reshape(-1)))\n",
    "        t_mask &= trial_ts < trial_behv['events']['t_stop'][0][0].reshape(-1)\n",
    "        if t_mask.sum() > 0:\n",
    "            t_mask[np.where(t_mask == True)[0][0]] = False # remove the first data point to avoid downsample error\n",
    "        \n",
    "        # get Y\n",
    "        mx = trial_behv['continuous']['xmp'][0][0][t_mask]\n",
    "        my = trial_behv['continuous']['ymp'][0][0][t_mask]\n",
    "        fx = trial_behv['continuous']['xfp'][0][0][t_mask]\n",
    "        fy = trial_behv['continuous']['yfp'][0][0][t_mask]\n",
    "        sx = np.ones_like(fx); sy = np.ones_like(fy)\n",
    "        if my.size > 0:\n",
    "            fx = np.ones_like(fx) * fx[0]\n",
    "            fy = np.ones_like(fy) * fy[0]\n",
    "            sx *= mx[-1]; sy *= my[-1]\n",
    "            my = my + 30; fy = fy + 30; sy = sy + 30\n",
    "        \n",
    "        dx = fx - mx; dy = fy - my\n",
    "        rel_dist = np.sqrt(dx**2 + dy**2); rel_ang = np.rad2deg(np.arctan2(dy, dx))\n",
    "        rel_dist_stop = np.sqrt((sx - mx)**2 + (sy - my)**2)\n",
    "        \n",
    "        if my.size > 0:\n",
    "            trials_error.append(rel_dist[-1][0])\n",
    "            trials_error_sign.append(rel_dist[-1][0])\n",
    "            trials_target_angle.append(np.rad2deg(np.arctan2(fy, fx))[-1][0] - 90)\n",
    "            trials_target_distance.append(np.sqrt(fx**2 + fy**2)[-1][0])\n",
    "            \n",
    "        else:\n",
    "            trials_error.append(np.nan)\n",
    "            trials_error_sign.append(np.nan)\n",
    "            trials_target_angle.append(np.nan)\n",
    "            trials_target_distance.append(np.nan)\n",
    "        \n",
    "        if my.size > 0:\n",
    "            d1 = np.sqrt(fx**2 + fy**2)\n",
    "            r1 = (fx**2 + fy**2) / (2*fx)\n",
    "            radian1 = 2 * r1 * np.arcsin(d1 / (2 * r1))\n",
    "\n",
    "            d2 = np.sqrt(mx**2 + my**2)\n",
    "            r2 = (mx**2 + my**2) / (2*mx + 1e-8)\n",
    "            radian2 = 2 * r2 * np.arcsin(d2 / (2 * r2 + 1e-8))\n",
    "\n",
    "            sign = np.ones_like(rel_dist)\n",
    "            sign[radian2 < radian1] = -1\n",
    "            rel_dist = sign * rel_dist\n",
    "            trials_error_sign[-1] = rel_dist[-1][0]\n",
    "        \n",
    "        abs_dist = np.sqrt(mx**2 + my**2); abs_ang = np.rad2deg(np.arctan2(my, mx))\n",
    "\n",
    "        hor_theta = trial_behv['continuous']['yre'][0][0][t_mask]\n",
    "        ver_theta = trial_behv['continuous']['zre'][0][0][t_mask]\n",
    "        mw = -trial_behv['continuous']['w'][0][0][t_mask].reshape(-1)\n",
    "        body_theta = np.deg2rad(np.cumsum(mw) * DT + 90)\n",
    "        body_x, body_y = mx.reshape(-1), my.reshape(-1)\n",
    "        \n",
    "        hor_theta_, ver_theta_ = convert_location_to_angle(abs(rel_dist).reshape(-1), fx.reshape(-1), fy.reshape(-1),\n",
    "                                                           body_theta, body_x, body_y, \n",
    "                                                           hor_theta.reshape(-1), ver_theta.reshape(-1))\n",
    "        \n",
    "               \n",
    "        mv = trial_behv['continuous']['v'][0][0][t_mask].reshape(-1,1)\n",
    "        mw = trial_behv['continuous']['w'][0][0][t_mask].reshape(-1,1)\n",
    "        if t_mask.sum() * DT > 3.5 or t_mask.sum() * DT < 0.6 or mv.max() < 50 or \\\n",
    "            abs_dist[-1] < np.sqrt(fx**2 + fy**2)[-1] * 0.3:\n",
    "            continue\n",
    "\n",
    "        target_variable = np.hstack([rel_dist, rel_ang, abs_dist, abs_ang,\n",
    "                                     hor_theta, ver_theta, hor_theta_, ver_theta_,\n",
    "                                     fx, fy, mx, my, mv, mw])\n",
    "        Y.append(target_variable)\n",
    "        target_variable = downsample(target_variable, bin_size=bin_size)\n",
    "        \n",
    "\n",
    "        # [0.0001 0.0005 0.001  0.005 ]\n",
    "        if trial_behv['prs'][0][0]['floordensity'] != density:\n",
    "            continue\n",
    "        \n",
    "        Ydownsampled.append([trial_idx, target_variable])\n",
    "   \n",
    "    m_extracted_continuous[key + 'Y'] = Y\n",
    "    m_downsampled[key + 'Ydownsampled'] = Ydownsampled\n",
    "\n",
    "    m_errors[key + 'error'] = trials_error; m_errors[key + 'error_sign'] = trials_error_sign\n",
    "    m_errors[key + 'target_angle'] = trials_target_angle; m_errors[key + 'target_distance'] = trials_target_distance\n",
    "    \n",
    "eval(m).update(m_downsampled); eval(m).update(m_extracted_continuous); eval(m).update(m_errors)\n",
    "del m_downsampled, m_extracted_continuous, m_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process the Y downsampled to irc input data (state, action, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m51s38Ydownsampled\n",
      "m51s40Ydownsampled\n",
      "m51s41Ydownsampled\n",
      "m51s42Ydownsampled\n",
      "m51s43Ydownsampled\n"
     ]
    }
   ],
   "source": [
    "irc_input_data={}\n",
    "\n",
    "for key, data in eval(m).items():\n",
    "    if not key.endswith('Ydownsampled'):\n",
    "        continue\n",
    "    states, actions, tasks=[],[],[]\n",
    "    \n",
    "    print(key)\n",
    "    y=eval(m)[key]\n",
    "    trial_idces, yy = zip(*y)\n",
    "\n",
    "    for itrial in range(len(trial_idces)):\n",
    "        rel_dist, rel_ang, abs_dist, abs_ang,hor_theta, ver_theta, hor_theta_, ver_theta_,fx, fy, mx, my, mv, mw=zip(*yy[itrial])\n",
    "        # task\n",
    "        taskx = (fx[0] - mx[0]).astype('float32'); tasky = (fy[0] - my[0]).astype('float32')\n",
    "        tasks.append([tasky/worldscale,taskx/worldscale])\n",
    "        # actions\n",
    "        trialaction=np.stack([mv,mw]).T\n",
    "        trialaction[:,0]=trialaction[:,0]/worldscale # v need reduce scale\n",
    "        trialaction[:,1]=trialaction[:,1]/180*pi\n",
    "        actions.append(trialaction.astype('float32'))\n",
    "\n",
    "        # states from run the actions\n",
    "        px, py, heading, v, w = 0,0,0,0,0\n",
    "        log=[]\n",
    "        for a in trialaction:\n",
    "            px, py, heading, v, w=state_step2(px, py, heading, v, w, a, dt=0.1,userad=True)\n",
    "            log.append([px, py, heading, v, w])\n",
    "        px, py, heading, v, w=state_step2(px, py, heading, v, w, a, dt=0.1,userad=True)\n",
    "        log.append([px, py, heading, v, w])\n",
    "        trialstates=np.array(log)[1:]\n",
    "        \n",
    "        states.append(trialstates.astype('float32'))\n",
    "\n",
    "    irc_input_data[key + '_irc']=(states, actions, tasks)\n",
    "\n",
    "eval(m).update(irc_input_data)\n",
    "del irc_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m51s38Ydownsampled_irc\n",
      "m51s40Ydownsampled_irc\n",
      "m51s41Ydownsampled_irc\n",
      "m51s42Ydownsampled_irc\n",
      "m51s43Ydownsampled_irc\n",
      "1192\n"
     ]
    }
   ],
   "source": [
    "all_states, all_actions, all_task=[],[],[]\n",
    "\n",
    "for k,v in eval(m).items():\n",
    "    if not k.endswith('irc'):\n",
    "        continue\n",
    "    print(k) # key\n",
    "\n",
    "    sess_states, sess_actions, sess_task=v\n",
    "    all_states+=sess_states\n",
    "    all_actions+=sess_actions\n",
    "    all_task+=sess_task\n",
    "\n",
    "print(len(all_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24455\\Desktop\\repo\\mkdata\\m51_mat_ruiyi\\preirc_den_3\n"
     ]
    }
   ],
   "source": [
    "# save the pre irc data\n",
    "\n",
    "with open(resdir/folder/(f'preirc_den_{idensity}'), 'wb+') as f:\n",
    "    pickle.dump((all_states, all_actions, all_task), f)\n",
    "print(resdir/folder/(f'preirc_den_{idensity}'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
