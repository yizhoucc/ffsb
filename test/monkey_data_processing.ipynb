{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.signal import medfilt\n",
    "from scipy.stats import norm\n",
    "import neo\n",
    "from pathlib import Path\n",
    "from rult import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonkeyDataExtractor():\n",
    "    def __init__(self, folder_path):\n",
    "        self.monkey_class = 'NYU' if 'NYU' in str(data_path) else 'BCM'\n",
    "        self.folder_path = folder_path\n",
    "        self.smr_full_file_path = sorted(self.folder_path.glob('*.smr'))\n",
    "        self.log_full_file_path = [file.parent / (file.stem + '.log') \n",
    "                                   for file in self.smr_full_file_path]\n",
    "        if self.monkey_class == 'NYU':\n",
    "            self.marker_memo = {'file_start': 1, 'trial_start': 2, 'trial_end': 3,\n",
    "                            'juice' :4, 'perturb_start': 8}\n",
    "        else:\n",
    "            self.marker_memo = {'file_start': 1, 'trial_start': 2, 'trial_end': 3,\n",
    "                            'juice' :4, 'perturb_start': 8, 'perturb_start2': 5}\n",
    "            \n",
    "        self.y_offset = 32.5\n",
    "            \n",
    "    def __call__(self):\n",
    "        if self.monkey_class == 'NYU':\n",
    "            self.nyu_extract_smr()\n",
    "            self.nyu_extract_log()\n",
    "            self.nyu_segment()\n",
    "        else:\n",
    "            self.bcm_extract_smr()\n",
    "            self.bcm_extract_log()\n",
    "            self.bcm_segment()\n",
    "            \n",
    "        return self.monkey_trajectory\n",
    "            \n",
    "    def nyu_extract_smr(self):\n",
    "        channel_signal_all = []\n",
    "        marker_all = []\n",
    "        \n",
    "        for idx, file_name in enumerate(self.smr_full_file_path):\n",
    "            seg_reader = neo.io.Spike2IO(filename=file_name).read_segment()\n",
    "            \n",
    "            if idx == 0: # only get sampling rate once\n",
    "                self.SAMPLING_RATE = seg_reader.analogsignals[0].sampling_rate.item()\n",
    "             \n",
    "            # Sometimes the length across channels varies a bit\n",
    "            analog_length = min([i.size for i in seg_reader.analogsignals])\n",
    "            channel_signal = np.ones((analog_length, seg_reader.size['analogsignals'] + 1))\n",
    "            \n",
    "            channel_names = []\n",
    "            for ch_idx, ch_data in enumerate(seg_reader.analogsignals):\n",
    "                channel_signal[:, ch_idx] = ch_data.as_array()[:analog_length].T\n",
    "                channel_names.append(ch_data.annotations['channel_names'][0])\n",
    "            \n",
    "            # Add a time channel\n",
    "            channel_signal[:, -1] = seg_reader.analogsignals[0].times[:analog_length]\n",
    "            channel_names.append('Time') \n",
    "            \n",
    "            channel_signal_all.append(pd.DataFrame(channel_signal, columns=channel_names))\n",
    "            \n",
    "            marker_channel_idx = [idx for idx, value \n",
    "                                    in enumerate(seg_reader.events)\n",
    "                                    if value.name == 'marker'][0]\n",
    "            marker_key, marker_time = (\n",
    "                seg_reader.events[marker_channel_idx].get_labels().astype('int'),\n",
    "                seg_reader.events[marker_channel_idx].as_array())\n",
    "            marker = {'key': marker_key, 'time': marker_time}\n",
    "            marker_all.append(marker)\n",
    "            \n",
    "            self.channel_signal_all = channel_signal_all\n",
    "            self.marker_all = marker_all\n",
    "            \n",
    "    def nyu_extract_log(self):\n",
    "        log_data_all = []\n",
    "        \n",
    "        for file_name in self.log_full_file_path:\n",
    "            with open(file_name, 'r', encoding='UTF-8') as content:\n",
    "                log_content = content.readlines()\n",
    "            \n",
    "            floor_density = []\n",
    "            perturb_vpeak = []; perturb_wpeak = []; perturb_start_time_ori = []\n",
    "            full_on = []; target_x = []; target_y = []\n",
    "            for line in log_content:\n",
    "                if 'Joy Stick Max Velocity' in line:\n",
    "                    gain_v = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Joy Stick Max Angular Velocity' in line:\n",
    "                    gain_w = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturb Max Velocity' in line:\n",
    "                    perturb_vpeakmax = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturb Max Angular Velocity' in line:\n",
    "                    perturb_wpeakmax = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturbation Sigma' in line:\n",
    "                    perturb_sigma = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturbation Duration' in line:\n",
    "                    perturb_dur = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Floor Density' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    floor_density.append(content_temp)\n",
    "                    \n",
    "                if 'Perturbation Linear Speed' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    perturb_vpeak.append(content_temp)\n",
    "                    \n",
    "                if 'Perturbation Angular Speed' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    perturb_wpeak.append(- content_temp)\n",
    "                    \n",
    "                if 'Perturbation Delay Time' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    perturb_start_time_ori.append(content_temp / 1000)  # ms to s\n",
    "                    \n",
    "                if 'Firefly Full On' in line:\n",
    "                    content_temp = bool(int(line.split(': ')[1]))\n",
    "                    full_on.append(content_temp)\n",
    "                \n",
    "                if 'Position x/y(cm)' in line:\n",
    "                    content_temp_x, content_temp_y = line.split(': ')[1].split(' ')\n",
    "                    target_x.append(float(content_temp_x))\n",
    "                    # Monkey data's y positions are reversed.\n",
    "                    target_y.append(- float(content_temp_y) + self.y_offset)\n",
    "                \n",
    "            log_data_all.append({'gain_v': gain_v, 'gain_w': gain_w,\n",
    "                                 'perturb_vpeakmax': perturb_vpeakmax, 'perturb_wpeakmax': perturb_wpeakmax,\n",
    "                                 'perturb_sigma': perturb_sigma, 'perturb_dur': perturb_dur,\n",
    "                                 'floor_density': floor_density,\n",
    "                                 'perturb_vpeak': perturb_vpeak, 'perturb_wpeak': perturb_wpeak,\n",
    "                                 'perturb_start_time_ori': perturb_start_time_ori,\n",
    "                                  'full_on': full_on, 'target_x': target_x, 'target_y': target_y})\n",
    "            \n",
    "            self.log_data_all = log_data_all\n",
    "            \n",
    "    def nyu_segment(self, lazy_threshold=4000, skip_threshold=400, skip_r_threshold=30, \n",
    "                    crazy_threshold=200,\n",
    "                    medfilt_kernel=5, v_threshold=1, reward_boundary=65, \n",
    "                    perturb_corr_threshold=50):\n",
    "        # lazy_threshold (data points): Trial is too long.\n",
    "        # skip_threshold (data points): Trial is too short.\n",
    "        # skip_r_threshold (cm): Monkey did not move a lot.\n",
    "        # crazy_threshold (cm): Monkey stopped too far.\n",
    "        # v_threshold (cm/s): Velocity threshold for start and end.\n",
    "        # reward_boundary (cm): Rewarded when stop inside this circular boundary.\n",
    "        # perturb_corr_threshold (data points): Corrected perturbation start index should not be too biased.\n",
    "        \n",
    "        gain_v = []; gain_w = []; perturb_vpeakmax = []; perturb_wpeakmax = []\n",
    "        perturb_sigma = []; perturb_dur = []; perturb_vpeak = []; perturb_wpeak = []\n",
    "        perturb_v = []; perturb_w = []; perturb_v_gauss = []; perturb_w_gauss = []\n",
    "        perturb_start_time = []; perturb_start_time_ori = []\n",
    "        floor_density = []; pos_x = []; pos_y = []\n",
    "        head_dir = []; head_dir_end = []; pos_r = []; pos_theta = []\n",
    "        pos_r_end = []; pos_theta_end = []\n",
    "        pos_v = []; pos_w = []; target_x = []; target_y = []\n",
    "        target_r = []; target_theta = []; full_on = []; rewarded = []\n",
    "        relative_radius = []; relative_angle = []; time = []\n",
    "        trial_dur = []; action_v = []; action_w = []\n",
    "        relative_radius_end = []; relative_angle_end = []; category = []\n",
    "\n",
    "        for session_idx, session_data in enumerate(self.channel_signal_all):\n",
    "            log_data = self.log_data_all[session_idx]\n",
    "            marker_data = self.marker_all[session_idx]\n",
    "            start_marker_times = marker_data['time'][\n",
    "                            marker_data['key'] == self.marker_memo['trial_start']]\n",
    "            end_marker_times = marker_data['time'][\n",
    "                            marker_data['key'] == self.marker_memo['trial_end']]\n",
    "            perturb_marker_times = marker_data['time'][\n",
    "                            marker_data['key'] == self.marker_memo['perturb_start']]\n",
    "\n",
    "            # segment trials\n",
    "            for trial_idx in range(end_marker_times.size):\n",
    "                trial_data = session_data[np.logical_and(\n",
    "                    session_data.Time > start_marker_times[trial_idx],\n",
    "                    session_data.Time < end_marker_times[trial_idx])].copy()\n",
    "                \n",
    "                # Use median filter kernel size as 5 to remove spike noise first.\n",
    "                trial_data['ForwardV'] = medfilt(trial_data['ForwardV'], medfilt_kernel)\n",
    "                trial_data['AngularV'] = medfilt(trial_data['AngularV'], medfilt_kernel)\n",
    "                \n",
    "                # cut non-moving head and tail\n",
    "                moving_period = np.where(trial_data['ForwardV'].abs() > v_threshold)[0]\n",
    "                if moving_period.size > 0:\n",
    "                    start_idx = moving_period[0]\n",
    "                    end_idx = moving_period[-1] + 2\n",
    "                else:\n",
    "                    start_idx = 0\n",
    "                    end_idx = None\n",
    "                  \n",
    "                # store trial data\n",
    "                trial_data = trial_data.iloc[start_idx : end_idx]\n",
    "                trial_data['AngularV'] = - trial_data['AngularV']\n",
    "                trial_data['MonkeyYa'] = np.cumsum(trial_data['AngularV']) / self.SAMPLING_RATE + 90\n",
    "                trial_data['MonkeyX'] = np.cumsum(trial_data['ForwardV']\n",
    "                                            * np.cos(np.deg2rad(trial_data['MonkeyYa']))) / self.SAMPLING_RATE\n",
    "                trial_data['MonkeyY'] = np.cumsum(trial_data['ForwardV']\n",
    "                                            * np.sin(np.deg2rad(trial_data['MonkeyYa']))) / self.SAMPLING_RATE\n",
    "                \n",
    "                gain_v.append(log_data['gain_v'])\n",
    "                gain_w.append(log_data['gain_w'])\n",
    "                perturb_vpeakmax.append(log_data['perturb_vpeakmax'])\n",
    "                perturb_wpeakmax.append(log_data['perturb_wpeakmax'])\n",
    "                perturb_vpeak.append(log_data['perturb_vpeak'][trial_idx])\n",
    "                perturb_wpeak.append(log_data['perturb_wpeak'][trial_idx])\n",
    "                perturb_start_time_ori.append(log_data['perturb_start_time_ori'][trial_idx])\n",
    "                perturb_sigma.append(log_data['perturb_sigma'])\n",
    "                perturb_dur.append(log_data['perturb_dur'])\n",
    "                pos_x.append(trial_data['MonkeyX'].values)\n",
    "                pos_y.append(trial_data['MonkeyY'].values)\n",
    "                head_dir.append(trial_data['MonkeyYa'].values)\n",
    "                head_dir_end.append(trial_data['MonkeyYa'].values[-1])\n",
    "                floor_density.append(log_data['floor_density'][trial_idx])\n",
    "                full_on.append(log_data['full_on'][trial_idx])\n",
    "\n",
    "                rho, phi = cart2pol(pos_x[-1], pos_y[-1])\n",
    "                pos_r.append(rho)\n",
    "                pos_theta.append(np.rad2deg(phi))\n",
    "                pos_r_end.append(rho[-1])\n",
    "                pos_theta_end.append(np.rad2deg(phi[-1]))\n",
    "                \n",
    "                \n",
    "                # determine if it is a perturbation trial\n",
    "                perturb_start_time_temp = perturb_marker_times[(np.logical_and(\n",
    "                                            perturb_marker_times > start_marker_times[trial_idx],\n",
    "                                            perturb_marker_times < end_marker_times[trial_idx]))]\n",
    "                if bool(perturb_start_time_temp.size):\n",
    "                    assert perturb_start_time_temp.size == 1\n",
    "                    pos_v.append(trial_data['ForwardV'].values)\n",
    "                    pos_w.append(trial_data['AngularV'].values)\n",
    "                    \n",
    "                    # construct perturbation curves\n",
    "                    perturb_xaxis = np.linspace(0, perturb_dur[-1], round(self.SAMPLING_RATE))\n",
    "                    perturb_temp = norm.pdf(perturb_xaxis, loc=perturb_dur[-1] / 2, scale=perturb_sigma[-1])\n",
    "                    perturb_temp /= perturb_temp.max()\n",
    "                    perturb_v_temp = perturb_temp * perturb_vpeak[-1]\n",
    "                    perturb_w_temp = perturb_temp * perturb_wpeak[-1]\n",
    "                    perturb_v_gauss.append(perturb_v_temp)\n",
    "                    perturb_w_gauss.append(perturb_w_temp)\n",
    "                    \n",
    "                    # use obvious angular perturbation curve as a template\n",
    "                    if abs(perturb_wpeak[-1]) / perturb_wpeakmax[-1] > 0.1:\n",
    "                        perturb_template = perturb_w_temp\n",
    "                        original_vel = pos_w[-1]\n",
    "                    else:\n",
    "                        perturb_template = perturb_v_temp\n",
    "                        original_vel = pos_v[-1]\n",
    "                        \n",
    "                    # use the template to do cross-correlation to find perturbation start time\n",
    "                    perturb_start_idx_mark = int((perturb_start_time_temp\n",
    "                                                - trial_data['Time'].values[0]) * self.SAMPLING_RATE)\n",
    "                    perturb_start_idx_mark = np.clip(perturb_start_idx_mark, 0, None)\n",
    "                    perturb_peak_idx = np.correlate(original_vel, perturb_template, mode='same').argsort()[::-1]\n",
    "                    perturb_start_idx_corr = perturb_peak_idx - perturb_dur[-1] / 2 * self.SAMPLING_RATE\n",
    "                    mask = (perturb_start_idx_corr > 0) \\\n",
    "                           & (perturb_start_idx_corr > perturb_start_idx_mark) \\\n",
    "                           & (perturb_start_idx_corr - perturb_start_idx_mark < perturb_corr_threshold)\n",
    "                    \n",
    "                    if mask.sum() == 0 or original_vel.size < perturb_template.size:\n",
    "                        perturb_start_idx = np.clip(perturb_start_idx_mark, None, pos_v[-1].size - 1)\n",
    "                    else:\n",
    "                        perturb_start_idx = int(perturb_start_idx_corr[mask][0])\n",
    "                    perturb_start_time.append(perturb_start_idx / self.SAMPLING_RATE)\n",
    "                    \n",
    "                    # get pure actions\n",
    "                    perturb_v_full = np.zeros_like(pos_v[-1])\n",
    "                    perturb_v_full[perturb_start_idx:perturb_start_idx + perturb_v_temp.size] = \\\n",
    "                                                            perturb_v_temp[:perturb_v_full.size - perturb_start_idx]\n",
    "                    perturb_w_full = np.zeros_like(pos_w[-1])\n",
    "                    perturb_w_full[perturb_start_idx:perturb_start_idx + perturb_w_temp.size] = \\\n",
    "                                                            perturb_w_temp[:perturb_w_full.size - perturb_start_idx]\n",
    "                    \n",
    "                    perturb_v.append(perturb_v_full); perturb_w.append(perturb_w_full)\n",
    "                    action_v.append((pos_v[-1] - perturb_v_full).clip(-gain_v[-1], gain_v[-1]) / gain_v[-1])\n",
    "                    action_w.append((pos_w[-1] - perturb_w_full).clip(-gain_w[-1], gain_w[-1]) / gain_w[-1])\n",
    "                else:\n",
    "                    pos_v.append(trial_data['ForwardV'].values.clip(-gain_v[-1], gain_v[-1]))\n",
    "                    pos_w.append(trial_data['AngularV'].values.clip(-gain_w[-1], gain_w[-1]))\n",
    "                    perturb_v_gauss.append(np.zeros(round(self.SAMPLING_RATE)))\n",
    "                    perturb_w_gauss.append(np.zeros(round(self.SAMPLING_RATE)))\n",
    "                    perturb_start_time.append(np.nan)\n",
    "                    perturb_v.append(np.zeros_like(pos_v[-1])); perturb_w.append(np.zeros_like(pos_w[-1]))\n",
    "                    action_v.append(pos_v[-1] / gain_v[-1])\n",
    "                    action_w.append(pos_w[-1] / gain_w[-1])\n",
    "                \n",
    "                trial_data['Time'] -= trial_data['Time'].iloc[0]\n",
    "                time.append(trial_data['Time'].values)\n",
    "                trial_dur.append(trial_data['Time'].values[-1])\n",
    "                target_x.append(log_data['target_x'][trial_idx])\n",
    "                target_y.append(log_data['target_y'][trial_idx])\n",
    "                tar_rho, tar_phi = cart2pol(target_x[-1], target_y[-1])\n",
    "                target_r.append(tar_rho)\n",
    "                target_theta.append(np.rad2deg(tar_phi))\n",
    "                \n",
    "                relative_r, relative_ang = get_relative_r_ang(\n",
    "                                pos_x[-1], pos_y[-1], head_dir[-1], target_x[-1], target_y[-1])\n",
    "                relative_radius.append(relative_r)\n",
    "                relative_angle.append(np.rad2deg(relative_ang))\n",
    "                relative_radius_end.append(relative_r[-1])\n",
    "                relative_angle_end.append(np.rad2deg(relative_ang[-1]))\n",
    "                rewarded.append(relative_r[-1] < reward_boundary)\n",
    "\n",
    "                # Categorize trials\n",
    "                if rewarded[-1]:\n",
    "                    category.append('normal')\n",
    "                else:\n",
    "                    if trial_data['ForwardV'].size < skip_threshold or\\\n",
    "                       pos_r_end[-1] < skip_r_threshold:\n",
    "                        category.append('skip')\n",
    "                    elif trial_data['ForwardV'].size > lazy_threshold:\n",
    "                        category.append('lazy')\n",
    "                    elif relative_r[-1] > crazy_threshold:\n",
    "                        category.append('crazy')\n",
    "                    else:\n",
    "                        category.append('normal')\n",
    "\n",
    "\n",
    "        # Construct a dataframe   \n",
    "        self.monkey_trajectory = pd.DataFrame().assign(gain_v=gain_v, gain_w=gain_w, \n",
    "                                 perturb_vpeakmax=perturb_vpeakmax, perturb_wpeakmax=perturb_wpeakmax,\n",
    "                                 perturb_sigma=perturb_sigma, perturb_dur=perturb_dur,\n",
    "                                 perturb_vpeak=perturb_vpeak, perturb_wpeak=perturb_wpeak,\n",
    "                                 perturb_start_time=perturb_start_time,\n",
    "                                 perturb_start_time_ori=perturb_start_time_ori,\n",
    "                                 perturb_v_gauss=perturb_v_gauss, perturb_w_gauss=perturb_w_gauss,\n",
    "                                 perturb_v=perturb_v, perturb_w=perturb_w,\n",
    "                                 floor_density=floor_density, pos_x=pos_x,\n",
    "                                 pos_y=pos_y, head_dir=head_dir, head_dir_end=head_dir_end,\n",
    "                                 pos_r=pos_r, pos_theta=pos_theta, pos_r_end=pos_r_end,\n",
    "                                 pos_theta_end=pos_theta_end, pos_v=pos_v, pos_w=pos_w, \n",
    "                                 target_x=target_x, target_y=target_y, target_r=target_r,\n",
    "                                 target_theta=target_theta, full_on=full_on, rewarded=rewarded,\n",
    "                                 relative_radius=relative_radius, relative_angle=relative_angle,\n",
    "                                 time=time, trial_dur=trial_dur, \n",
    "                                 action_v=action_v, action_w=action_w, \n",
    "                                 relative_radius_end=relative_radius_end,\n",
    "                                 relative_angle_end=relative_angle_end, category=category)\n",
    "\n",
    "\n",
    "    def bcm_extract_smr(self):\n",
    "        channel_signal_all = []\n",
    "        marker_all = []\n",
    "        \n",
    "        for idx, file_name in enumerate(self.smr_full_file_path):\n",
    "            seg_reader = neo.io.Spike2IO(filename=file_name).read_segment()\n",
    "            \n",
    "            if idx == 0: # only get sampling rate once\n",
    "                self.SAMPLING_RATE = seg_reader.analogsignals[0].sampling_rate.item()\n",
    "                \n",
    "            # Sometimes the length across channels varies a bit\n",
    "            analog_length = min([i.size for i in seg_reader.analogsignals])\n",
    "            channel_signal = np.ones((analog_length, seg_reader.size['analogsignals']))\n",
    "            \n",
    "            channel_names = []\n",
    "            # Do not read the last channel as it has a unique shape.\n",
    "            for ch_idx, ch_data in enumerate(seg_reader.analogsignals[:-1]):\n",
    "                channel_signal[:, ch_idx] = ch_data.as_array()[:analog_length].T\n",
    "                channel_names.append(ch_data.annotations['channel_names'][0])\n",
    "            \n",
    "            # Add a time channel\n",
    "            channel_signal[:, -1] = seg_reader.analogsignals[0].times[:analog_length]\n",
    "            channel_names.append('Time') \n",
    "            \n",
    "            channel_signal_all.append(pd.DataFrame(channel_signal,columns=channel_names))\n",
    "            \n",
    "            marker_channel_idx = [idx for idx, value \n",
    "                                    in enumerate(seg_reader.events)\n",
    "                                    if value.name == 'marker'][0]\n",
    "            marker_key, marker_time = (\n",
    "                seg_reader.events[marker_channel_idx].get_labels().astype('int'),\n",
    "                seg_reader.events[marker_channel_idx].as_array())\n",
    "            marker = {'key': marker_key, 'time': marker_time}\n",
    "            marker_all.append(marker)\n",
    "            \n",
    "            self.channel_signal_all = channel_signal_all\n",
    "            self.marker_all = marker_all\n",
    "            \n",
    "    def bcm_extract_log(self):\n",
    "        log_data_all = []\n",
    "        \n",
    "        for file_name in self.log_full_file_path:\n",
    "            with open(file_name, 'r', encoding='UTF-8') as content:\n",
    "                log_content = content.readlines()\n",
    "                \n",
    "            floor_density = []\n",
    "            perturb_vpeak = []; perturb_wpeak = []\n",
    "            perturb_start_time_ori = []\n",
    "            full_on = []\n",
    "            for line in log_content:\n",
    "                if 'Joy Stick Max Velocity' in line:\n",
    "                    gain_v = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Joy Stick Max Angular Velocity' in line:\n",
    "                    gain_w = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturb Max Velocity' in line:\n",
    "                    perturb_vpeakmax = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturb Max Angular Velocity' in line:\n",
    "                    perturb_wpeakmax = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturbation Sigma' in line:\n",
    "                    perturb_sigma = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Perturbation Duration' in line:\n",
    "                    perturb_dur = float(line.split(': ')[1])\n",
    "                    \n",
    "                if 'Floor Density' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    floor_density.append(content_temp)\n",
    "                    \n",
    "                if 'Perturbation Linear Speed' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    perturb_vpeak.append(content_temp)\n",
    "                    \n",
    "                if 'Perturbation Angular Speed' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    perturb_wpeak.append(- content_temp)\n",
    "                    \n",
    "                if 'Perturbation Delay Time' in line:\n",
    "                    content_temp = float(line.split(': ')[1])\n",
    "                    perturb_start_time_ori.append(content_temp / 1000)\n",
    "                    \n",
    "                if 'Firefly Full ON' in line:\n",
    "                    content_temp = bool(int(line.split(': ')[1]))\n",
    "                    full_on.append(content_temp)\n",
    "            \n",
    "            if len(full_on) == 0: # Quigley's perturbation sessions\n",
    "                full_on = [False] * len(floor_density)\n",
    "            \n",
    "            log_data_all.append({'gain_v': gain_v, 'gain_w': gain_w, \n",
    "                                 'perturb_vpeakmax': perturb_vpeakmax, 'perturb_wpeakmax': perturb_wpeakmax,\n",
    "                                 'perturb_sigma': perturb_sigma, 'perturb_dur': perturb_dur,\n",
    "                                 'floor_density': floor_density, \n",
    "                                 'perturb_vpeak': perturb_vpeak, 'perturb_wpeak': perturb_wpeak,\n",
    "                                 'perturb_start_time_ori': perturb_start_time_ori,\n",
    "                                 'full_on': full_on})\n",
    "            self.log_data_all = log_data_all\n",
    "            \n",
    "    def bcm_segment(self, lazy_threshold=4000, skip_threshold=400, skip_r_threshold=30, \n",
    "                    crazy_threshold=200,\n",
    "                    medfilt_kernel=5, v_threshold=1, reward_boundary=65,\n",
    "                    target_r_range=[100, 400], target_theta_range=[55, 125], \n",
    "                    target_tolerance=1, perturb_corr_threshold=100):\n",
    "        # lazy_threshold (data points): Trial is too long.\n",
    "        # skip_threshold (data points): Trial is too short.\n",
    "        # skip_r_threshold (cm): Monkey did not move a lot.\n",
    "        # crazy_threshold (cm): Monkey stopped too far.\n",
    "        # medfilt_kernel (data points): Remove spikes from raw data.\n",
    "        # v_threshold (cm/s): Threshold for end point.\n",
    "        # reward_boundary (cm): Rewarded when stop inside this circular boundary.\n",
    "        # target_r_range (cm): Radius of target distribution.\n",
    "        # target_theta_range (deg): Angle of target distribution.\n",
    "        # target_tolerance (cm or deg): Max tolerance for targets out of distribution.\n",
    "        # perturb_corr_threshold (data points): Corrected perturbation start index should not be too biased.\n",
    "\n",
    "        gain_v = []; gain_w = []; perturb_vpeakmax = []; perturb_wpeakmax = []\n",
    "        perturb_sigma = []; perturb_dur = []; perturb_vpeak = []; perturb_wpeak = []\n",
    "        perturb_v = []; perturb_w = []; perturb_v_gauss = []; perturb_w_gauss = []\n",
    "        perturb_start_time = []; perturb_start_time_ori = []\n",
    "        floor_density = []; pos_x = []; pos_y = []\n",
    "        head_dir = []; head_dir_end = []; pos_r = []; pos_theta = []; \n",
    "        pos_r_end = []; pos_theta_end = []\n",
    "        pos_v = []; pos_w = []; target_x = []; target_y = []\n",
    "        target_r = []; target_theta = []; full_on = []; rewarded = []\n",
    "        relative_radius = []; relative_angle = []; time = []; \n",
    "        trial_dur = []; action_v = []; action_w = []; \n",
    "        relative_radius_end = []; relative_angle_end = []; category = []\n",
    "\n",
    "        for session_idx, session_data in enumerate(self.channel_signal_all):\n",
    "            log_data = self.log_data_all[session_idx]\n",
    "            marker_data = self.marker_all[session_idx]\n",
    "            start_marker_times = marker_data['time'][\n",
    "                            marker_data['key'] == self.marker_memo['trial_start']]\n",
    "            end_marker_times = marker_data['time'][\n",
    "                            marker_data['key'] == self.marker_memo['trial_end']]\n",
    "            perturb_marker_times = marker_data['time'][\n",
    "                            marker_data['key'] == self.marker_memo['perturb_start']]\n",
    "            if perturb_marker_times.size == 0:\n",
    "                perturb_marker_times = marker_data['time'][\n",
    "                            marker_data['key'] == self.marker_memo['perturb_start2']]\n",
    "\n",
    "            # segment trials\n",
    "            for trial_idx in range(end_marker_times.size):\n",
    "                trial_data = session_data[np.logical_and(\n",
    "                    session_data.Time > start_marker_times[trial_idx],\n",
    "                    session_data.Time < end_marker_times[trial_idx])].copy()\n",
    "\n",
    "                # Use median filter kernel size as 5 to remove spike noise first.\n",
    "                trial_data['ForwardV'] = medfilt(trial_data['ForwardV'], medfilt_kernel)\n",
    "                trial_data['AngularV'] = medfilt(trial_data['AngularV'], medfilt_kernel)\n",
    "                \n",
    "                # cut non-moving head and tail\n",
    "                moving_period = np.where(trial_data['ForwardV'].abs() > v_threshold)[0]\n",
    "                if moving_period.size > 0:\n",
    "                    start_idx = moving_period[0]\n",
    "                    end_idx = moving_period[-1] + 2\n",
    "                else:\n",
    "                    start_idx = 0\n",
    "                    end_idx = None\n",
    "                    \n",
    "                # store trial data\n",
    "                trial_data = trial_data.iloc[start_idx : end_idx]\n",
    "                trial_data['AngularV'] = - trial_data['AngularV']\n",
    "                trial_data['MonkeyYa'] = np.cumsum(trial_data['AngularV']) / self.SAMPLING_RATE + 90\n",
    "                trial_data['MonkeyX'] = np.cumsum(trial_data['ForwardV']\n",
    "                                            * np.cos(np.deg2rad(trial_data['MonkeyYa']))) / self.SAMPLING_RATE\n",
    "                trial_data['MonkeyY'] = np.cumsum(trial_data['ForwardV']\n",
    "                                            * np.sin(np.deg2rad(trial_data['MonkeyYa']))) / self.SAMPLING_RATE\n",
    "                \n",
    "                gain_v.append(log_data['gain_v'])\n",
    "                gain_w.append(log_data['gain_w'])\n",
    "                perturb_vpeakmax.append(log_data['perturb_vpeakmax'])\n",
    "                perturb_wpeakmax.append(log_data['perturb_wpeakmax'])\n",
    "                perturb_vpeak.append(log_data['perturb_vpeak'][trial_idx])\n",
    "                perturb_wpeak.append(log_data['perturb_wpeak'][trial_idx])\n",
    "                perturb_start_time_ori.append(log_data['perturb_start_time_ori'][trial_idx])\n",
    "                perturb_sigma.append(log_data['perturb_sigma'])\n",
    "                perturb_dur.append(log_data['perturb_dur'])\n",
    "                pos_x.append(trial_data['MonkeyX'].values)\n",
    "                pos_y.append(trial_data['MonkeyY'].values)\n",
    "                head_dir.append(trial_data['MonkeyYa'].values)\n",
    "                head_dir_end.append(trial_data['MonkeyYa'].values[-1])\n",
    "                floor_density.append(log_data['floor_density'][trial_idx])\n",
    "                full_on.append(log_data['full_on'][trial_idx])\n",
    "                \n",
    "                rho, phi = cart2pol(pos_x[-1], pos_y[-1])\n",
    "                pos_r.append(rho)\n",
    "                pos_theta.append(np.rad2deg(phi))\n",
    "                pos_r_end.append(rho[-1])\n",
    "                pos_theta_end.append(np.rad2deg(phi[-1]))\n",
    "                \n",
    "                \n",
    "                # determine if it is a perturbation trial\n",
    "                perturb_start_time_temp = perturb_marker_times[(np.logical_and(\n",
    "                                            perturb_marker_times > start_marker_times[trial_idx],\n",
    "                                            perturb_marker_times < end_marker_times[trial_idx]))]\n",
    "                if bool(perturb_start_time_temp.size):\n",
    "                    assert perturb_start_time_temp.size == 1\n",
    "                    pos_v.append(trial_data['ForwardV'].values)\n",
    "                    pos_w.append(trial_data['AngularV'].values)\n",
    "                \n",
    "                    # construct perturbation curves\n",
    "                    perturb_xaxis = np.linspace(0, perturb_dur[-1], round(self.SAMPLING_RATE))\n",
    "                    perturb_temp = norm.pdf(perturb_xaxis, loc=perturb_dur[-1] / 2, scale=perturb_sigma[-1])\n",
    "                    perturb_temp /= perturb_temp.max()\n",
    "                    perturb_v_temp = perturb_temp * perturb_vpeak[-1]\n",
    "                    perturb_w_temp = perturb_temp * perturb_wpeak[-1]\n",
    "                    perturb_v_gauss.append(perturb_v_temp)\n",
    "                    perturb_w_gauss.append(perturb_w_temp)\n",
    "                    \n",
    "                    # use the more obvious perturbation curve as a template\n",
    "                    corrcoef_v = np.correlate(pos_v[-1] - pos_v[-1].mean(), \n",
    "                                              perturb_v_temp - perturb_v_temp.mean(),\n",
    "                                              mode='same') / (pos_v[-1].std() * perturb_v_temp.std())\n",
    "                    corrcoef_w = np.correlate(pos_w[-1] - pos_w[-1].mean(), \n",
    "                                              perturb_w_temp - perturb_w_temp.mean(),\n",
    "                                              mode='same') / (pos_w[-1].std() * perturb_w_temp.std())\n",
    "                    if corrcoef_v.max() > corrcoef_w.max():\n",
    "                        perturb_template = perturb_v_temp\n",
    "                        original_vel = pos_v[-1]\n",
    "                    else:\n",
    "                        perturb_template = perturb_w_temp\n",
    "                        original_vel = pos_w[-1]\n",
    "                        \n",
    "                    # use the template to do cross-correlation to find perturbation start time\n",
    "                    perturb_start_idx_mark = int((perturb_start_time_temp\n",
    "                                                - trial_data['Time'].values[0]) * self.SAMPLING_RATE)\n",
    "                    perturb_start_idx_mark = np.clip(perturb_start_idx_mark, 0, None)\n",
    "                    perturb_peak_idx = np.correlate(original_vel, perturb_template, mode='same').argsort()[::-1]\n",
    "                    perturb_start_idx_corr = perturb_peak_idx - perturb_dur[-1] / 2 * self.SAMPLING_RATE\n",
    "                    mask = (perturb_start_idx_corr > 0) \\\n",
    "                           & (perturb_start_idx_corr > perturb_start_idx_mark) \\\n",
    "                           & (perturb_start_idx_corr - perturb_start_idx_mark < perturb_corr_threshold)\n",
    "                    \n",
    "                    if mask.sum() == 0 or original_vel.size < perturb_template.size:\n",
    "                        perturb_start_idx = np.clip(perturb_start_idx_mark, None, pos_v[-1].size - 1)\n",
    "                    else:\n",
    "                        perturb_start_idx = int(perturb_start_idx_corr[mask][0])\n",
    "                    perturb_start_time.append(perturb_start_idx / self.SAMPLING_RATE)\n",
    "                    \n",
    "                    # get pure actions\n",
    "                    perturb_v_full = np.zeros_like(pos_v[-1])\n",
    "                    perturb_v_full[perturb_start_idx:perturb_start_idx + perturb_v_temp.size] = \\\n",
    "                                                            perturb_v_temp[:perturb_v_full.size - perturb_start_idx]\n",
    "                    perturb_w_full = np.zeros_like(pos_w[-1])\n",
    "                    perturb_w_full[perturb_start_idx:perturb_start_idx + perturb_w_temp.size] = \\\n",
    "                                                            perturb_w_temp[:perturb_w_full.size - perturb_start_idx]\n",
    "                    \n",
    "                    perturb_v.append(perturb_v_full); perturb_w.append(perturb_w_full)\n",
    "                    action_v.append((pos_v[-1] - perturb_v_full).clip(-gain_v[-1], gain_v[-1]) / gain_v[-1])\n",
    "                    action_w.append((pos_w[-1] - perturb_w_full).clip(-gain_w[-1], gain_w[-1]) / gain_w[-1])\n",
    "                else:\n",
    "                    pos_v.append(trial_data['ForwardV'].values.clip(-gain_v[-1], gain_v[-1]))\n",
    "                    pos_w.append(trial_data['AngularV'].values.clip(-gain_w[-1], gain_w[-1]))\n",
    "                    perturb_v_gauss.append(np.zeros(round(self.SAMPLING_RATE)))\n",
    "                    perturb_w_gauss.append(np.zeros(round(self.SAMPLING_RATE)))\n",
    "                    perturb_start_time.append(np.nan)\n",
    "                    perturb_v.append(np.zeros_like(pos_v[-1])); perturb_w.append(np.zeros_like(pos_w[-1]))\n",
    "                    action_v.append(pos_v[-1] / gain_v[-1])\n",
    "                    action_w.append(pos_w[-1] / gain_w[-1])\n",
    "                \n",
    "\n",
    "                trial_data['Time'] -= trial_data['Time'].iloc[0]\n",
    "                time.append(trial_data['Time'].values)\n",
    "                trial_dur.append(trial_data['Time'].values[-1])\n",
    "                \n",
    "                \n",
    "                # target position is analog in BCM data, I bin target channels\n",
    "                # and find the mode of bins\n",
    "                targetx_bins = np.arange(my_floor(trial_data['FireflyX'].min(), 1),\n",
    "                                         my_ceil(trial_data['FireflyX'].max(), 1), 0.1)\n",
    "                targetx_idxes = np.digitize(trial_data['FireflyX'], targetx_bins)\n",
    "                targetx_hist, _ = np.histogram(trial_data['FireflyX'], targetx_bins)\n",
    "                try:\n",
    "                    tar_x = trial_data['FireflyX'][\n",
    "                                    targetx_idxes == targetx_hist.argmax()+1].mean()\n",
    "                except: # when start_idx == end_idx, they are bad trials that not matter\n",
    "                    tar_x = trial_data['FireflyX'].mean()\n",
    "\n",
    "                targety_bins = np.arange(my_floor(trial_data['FireflyY'].min(), 1),\n",
    "                                         my_ceil(trial_data['FireflyY'].max(), 1), 0.1)\n",
    "                targety_idxes = np.digitize(trial_data['FireflyY'], targety_bins)\n",
    "                targety_hist, _ = np.histogram(trial_data['FireflyY'], targety_bins)\n",
    "                try:\n",
    "                    tar_y = trial_data['FireflyY'][\n",
    "                                    targety_idxes == targety_hist.argmax()+1].mean()\n",
    "                except:\n",
    "                    tar_y = trial_data['FireflyY'].mean()\n",
    "\n",
    "                target_x.append(tar_x)\n",
    "                target_y.append(- tar_y + self.y_offset)\n",
    "                tar_rho, tar_phi = cart2pol(target_x[-1], target_y[-1])\n",
    "                target_r.append(tar_rho)\n",
    "                target_theta.append(np.rad2deg(tar_phi))\n",
    "\n",
    "                relative_r, relative_ang = get_relative_r_ang(\n",
    "                                pos_x[-1], pos_y[-1], head_dir[-1], target_x[-1], target_y[-1])\n",
    "                relative_radius.append(relative_r)\n",
    "                relative_angle.append(np.rad2deg(relative_ang))\n",
    "                relative_radius_end.append(relative_r[-1])\n",
    "                relative_angle_end.append(np.rad2deg(relative_ang[-1]))\n",
    "                rewarded.append(relative_r[-1] < reward_boundary)\n",
    "\n",
    "                #juice_time = marker_data['time'][marker_data['key'] == marker_memo['juice']]\n",
    "                #j_marker = np.where(np.logical_and(juice_time > start_marker_times[trial_idx],\n",
    "                #               juice_time < end_marker_times[trial_idx]))[0]\n",
    "\n",
    "                # Categorize trials\n",
    "                # Note that few targets in BCM data are out of the distribution\n",
    "                # for unknown reason, I just label and ignore them.\n",
    "                if target_r[-1] < target_r_range[0] - target_tolerance or\\\n",
    "                   target_r[-1] > target_r_range[1] + target_tolerance or\\\n",
    "                   target_theta[-1] < target_theta_range[0] - target_tolerance or\\\n",
    "                   target_theta[-1] > target_theta_range[1] + target_tolerance:\n",
    "                    category.append('wrong_target')\n",
    "                else:\n",
    "                    if rewarded[-1]:\n",
    "                        category.append('normal')\n",
    "                    else:\n",
    "                        if trial_data['ForwardV'].size < skip_threshold or\\\n",
    "                           pos_r_end[-1] < skip_r_threshold:\n",
    "                            category.append('skip')\n",
    "                        elif trial_data['ForwardV'].size > lazy_threshold:\n",
    "                            category.append('lazy')\n",
    "                        elif relative_r[-1] > crazy_threshold:\n",
    "                            category.append('crazy')\n",
    "                        else:\n",
    "                            category.append('normal')\n",
    "\n",
    "        # Construct a dataframe   \n",
    "        self.monkey_trajectory = pd.DataFrame().assign(gain_v=gain_v, gain_w=gain_w, \n",
    "                                 perturb_vpeakmax=perturb_vpeakmax, perturb_wpeakmax=perturb_wpeakmax,\n",
    "                                 perturb_sigma=perturb_sigma, perturb_dur=perturb_dur,\n",
    "                                 perturb_vpeak=perturb_vpeak, perturb_wpeak=perturb_wpeak,\n",
    "                                 perturb_start_time=perturb_start_time,\n",
    "                                 perturb_start_time_ori=perturb_start_time_ori,\n",
    "                                 perturb_v_gauss=perturb_v_gauss, perturb_w_gauss=perturb_w_gauss,\n",
    "                                 perturb_v=perturb_v, perturb_w=perturb_w,\n",
    "                                 floor_density=floor_density, pos_x=pos_x,\n",
    "                                 pos_y=pos_y, head_dir=head_dir, head_dir_end=head_dir_end,\n",
    "                                 pos_r=pos_r, pos_theta=pos_theta, pos_r_end=pos_r_end,\n",
    "                                 pos_theta_end=pos_theta_end, pos_v=pos_v, pos_w=pos_w, \n",
    "                                 target_x=target_x, target_y=target_y, target_r=target_r,\n",
    "                                 target_theta=target_theta, full_on=full_on, rewarded=rewarded,\n",
    "                                 relative_radius=relative_radius, relative_angle=relative_angle,\n",
    "                                 time=time, trial_dur=trial_dur, \n",
    "                                 action_v=action_v, action_w=action_w, \n",
    "                                 relative_radius_end=relative_radius_end,\n",
    "                                 relative_angle_end=relative_angle_end, category=category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\mkdata\\\\Bruno_density/06-13-2017'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path=\"D:\\mkdata\\Bruno_density\"\n",
    "import os\n",
    "sessions=os.listdir(data_path)\n",
    "\n",
    "\n",
    "i=sessions[0]\n",
    "j=data_path+'/'+i\n",
    "# files=os.listdir(j)\n",
    "# k=files[1]\n",
    "# file=j+'/'+k\n",
    "j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid annotation. Annotations of type <class 'pathlib.WindowsPath'> are notallowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a3226e0c1e59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMonkeyDataExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-c2f1adafcc0f>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnyu_segment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbcm_extract_smr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbcm_extract_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbcm_segment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-c2f1adafcc0f>\u001b[0m in \u001b[0;36mbcm_extract_smr\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmr_full_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0mseg_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpike2IO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_segment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# only get sampling rate once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\io\\basefromrawio.py\u001b[0m in \u001b[0;36mread_segment\u001b[1;34m(self, block_index, seg_index, lazy, signal_group_mode, load_waveforms, time_slice, strict_slicing)\u001b[0m\n\u001b[0;32m    249\u001b[0m                     \u001b[1;31m# make a proxy...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                     anasig = AnalogSignalProxy(rawio=self, global_channel_indexes=ind_abs,\n\u001b[1;32m--> 251\u001b[1;33m                                     block_index=block_index, seg_index=seg_index)\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\io\\proxyobjects.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, rawio, global_channel_indexes, block_index, seg_index)\u001b[0m\n\u001b[0;32m    148\u001b[0m                                                 d, self._global_channel_indexes))\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mBaseProxy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_annotations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marray_annotations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_indexes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\io\\proxyobjects.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, array_annotations, **annotations)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_annotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArrayDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0marray_annotations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_annotations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_annotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mBaseNeo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\core\\dataobject.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\core\\dataobject.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;31m# Need to wrap key and value in a dict in order to make sure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;31m# that nested dicts are detected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\core\\dataobject.py\u001b[0m in \u001b[0;36m_normalize_array_annotations\u001b[1;34m(value, length)\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nested dicts are not allowed as array annotations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_normalize_array_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\core\\dataobject.py\u001b[0m in \u001b[0;36m_normalize_array_annotations\u001b[1;34m(value, length)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;31m# Perform check on first element\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[0m_check_single_elem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\core\\dataobject.py\u001b[0m in \u001b[0;36m_check_single_elem\u001b[1;34m(element)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;31m# Perform regular check for elements of array or list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0m_check_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Arrays only need testing of single element to make sure the others are the same\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\lab\\lib\\site-packages\\neo\\core\\baseneo.py\u001b[0m in \u001b[0;36m_check_annotations\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mALLOWED_ANNOTATION_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         raise ValueError(\"Invalid annotation. Annotations of type %s are not\"\n\u001b[1;32m---> 52\u001b[1;33m                          \"allowed\" % type(value))\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid annotation. Annotations of type <class 'pathlib.WindowsPath'> are notallowed"
     ]
    }
   ],
   "source": [
    "data_path=j\n",
    "ext=MonkeyDataExtractor(folder_path=Path(data_path))\n",
    "tra=ext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for f in glob.glob(j+\"/*\", recursive=True):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Path.glob of WindowsPath('D:/mkdata/Bruno_density/06-13-2017')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(j).glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "9592d15aceb5d430ee442cb9ede5dd79fb3ce6f4446604e3ec7196d8b17be17b"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
